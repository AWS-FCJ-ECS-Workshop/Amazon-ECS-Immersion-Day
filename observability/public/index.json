[
{
	"uri": "//localhost:1313/1-container-insights/",
	"title": "Container Insights",
	"tags": [],
	"description": "",
	"content": "\rPrerequisites: Complete the Fundamentals \u0026amp; ECS Service Connect chapter before starting this lab.\nBy default, Amazon ECS provides metrics for clusters and services. However, by opting into Container Insights, you can enhance operational convenience by gaining access to additional metrics that facilitate operational management. CloudWatch Container Insights collects, aggregates, and summarizes metrics and logs from your containerized applications and microservices. You can also set CloudWatch alarms on metrics that Container Insights collects.\nIn this lab, we will first check whether Container Insights are enabled on your Amazon ECS Cluster. If Container Insights are not enabled, we will use AWS CLI to enable them for CloudWatch.\nCheck the status of Container Insights for the ECS cluster by filtering the AWS CLI output from describe-clusters . The output from the AWS CLI query will return the Container Insights status to indicate whether it is enabled or disabled for the ECS Cluster.\naws ecs describe-clusters --clusters retail-store-ecs-cluster --include SETTINGS --query \u0026#39;clusters[*].settings\u0026#39; Expand in case the Container Insight is not enabled. If Container Insights are not enabled, use the following AWS CLI command to enable Container Insights for CloudWatch:\naws ecs update-cluster-settings --cluster retail-store-ecs-cluster --settings name=containerInsights,value=enabled You should receive the following output in the command line:\n{\r\u0026#34;cluster\u0026#34;: {\r\u0026#34;clusterArn\u0026#34;: \u0026#34;arn:aws:ecs:us-west-2:XXXXXXXXXX:cluster/retail-store-ecs-cluster\u0026#34;,\r\u0026#34;clusterName\u0026#34;: \u0026#34;retail-store-ecs-cluster\u0026#34;,\r\u0026#34;status\u0026#34;: \u0026#34;ACTIVE\u0026#34;,\r\u0026#34;registeredContainerInstancesCount\u0026#34;: 0,\r\u0026#34;runningTasksCount\u0026#34;: 0,\r\u0026#34;pendingTasksCount\u0026#34;: 0,\r\u0026#34;activeServicesCount\u0026#34;: 0,\r\u0026#34;statistics\u0026#34;: [],\r\u0026#34;tags\u0026#34;: [],\r\u0026#34;settings\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;containerInsights\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;enabled\u0026#34;\r}\r],\r\u0026#34;capacityProviders\u0026#34;: [],\r\u0026#34;defaultCapacityProviderStrategy\u0026#34;: [],\r\u0026#34;attachments\u0026#34;: []\r}\r} "
},
{
	"uri": "//localhost:1313/1-container-insights/1-container-insights-metrics/",
	"title": "Container Insights metrics",
	"tags": [],
	"description": "",
	"content": "CloudWatch Container Insights collects metrics and logs from your containerized applications and microservices. It employs a containerized CloudWatch agent to discover and gather performance data from all running containers in a cluster. This data is then utilized to generate aggregated metrics at the cluster, service, and task levels, including resource utilization metrics for CPU, memory, disk, and network.\nWhen you need regular statistics on aggregated data over time, it\u0026rsquo;s preferable to use metrics rather than logs. Metrics are ideal for creating alarms or dashboard graphs.\nExplore Container Insights metrics To explore metrics, first open the CloudWatch Container Insights console:\nOpen Amazon CloudWatch console\rIn the CloudWatch console, select Service: ECS from the Service dropdown and Performance Monitoring from the second dropdown at the top. Then, choose the retail-store-ecs-cluster. Finally, change ECS Cluster to ECS Services.\nYou can observe various metrics such as CPU Utilization, Memory Utilization, Network RX/TX, and Ephemeral Storage Utilization. These key metrics and automated dashboards are automatically generated by CloudWatch Container Insights based on the retail-store-ecs-cluster. Since these metrics are also available in CloudWatch Metrics, they can be used for creating custom dashboards as well.\nAmazon ECS Container Insights metrics are located in the ECS/ContainerInsights namespace. For detailed information about each metric, please refer to the documentation here.\nExplore application\u0026rsquo;s visual map To see a graphical representation of the ECS resources and their relationships, click on View in maps in the top right-hand side menu.\nIf you hover your mouse over one of the resources, you can view more details such as CPU, memory utilization, network traffic, and disk utilization.\n"
},
{
	"uri": "//localhost:1313/1-container-insights/2-explore-cloudwatch-logs/",
	"title": "Explore CloudWatch Logs",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s review the logs from the retail store cluster\u0026rsquo;s applications and check the logs related to this cluster\u0026rsquo;s performance.\nExplore Application Log We configured the log settings for the UI container service in the ECS task definition section as follows. We used the default awslogs driver to collect logs from the container and a log group, which represents a group of log streams that share the same retention, monitoring, and access control settings.\n\u0026#34;logConfiguration\u0026#34;: {\r\u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;,\r\u0026#34;options\u0026#34;: {\r\u0026#34;awslogs-group\u0026#34;: \u0026#34;retail-store-ecs-tasks\u0026#34;,\r\u0026#34;awslogs-region\u0026#34;: \u0026#34;$AWS_REGION\u0026#34;,\r\u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ui-service\u0026#34;\r}\r} Navigate to the Log groups menu in CloudWatch. Search for the retail-store-ecs-tasks log group and click on it to view the UI and catalog-related log streams as shown below.\nA log stream comprises a series of log events originating from the same source. Each distinct source of logs within CloudWatch Logs constitutes its own log stream.\nMove to the Logs Insights for analyzing application log data with CloudWatch Logs Insights. Select retail-store-ecs-tasks for the log group and run the following query. As a result, you can retrieve the logs related to the UI service. The results will be displayed as a bar graph of log events in this log group over time.\nfields @timestamp, @logStream, @message\r| filter @logStream like /catalog-service/\r| sort @timestamp desc\r| limit 10 "
},
{
	"uri": "//localhost:1313/1-container-insights/3-load-testing-ecs-microservices/",
	"title": "Load Testing ECS Microservices",
	"tags": [],
	"description": "",
	"content": "In this section, we\u0026rsquo;ll generate synthetic load using the stress command, which is a command-line tool for Linux-based operating systems to introduce load into the system. We will exec into the ui task and run the stress command to trigger scaling. We will then observe the CloudWatch metrics to see the scaling effect.\nConnect to the ECS Task Run the following command to select one of the running tasks with enableExecuteCommand enabled:\nECS_EXEC_TASK_ARN=$(aws ecs list-tasks --cluster retail-store-ecs-cluster \\\r--service-name ui --query \u0026#39;taskArns[]\u0026#39; --output text | \\\rxargs -n1 aws ecs describe-tasks --cluster retail-store-ecs-cluster --tasks | \\\rjq -r \u0026#39;.tasks[] | select(.enableExecuteCommand == true) | .taskArn\u0026#39; | \\\rhead -n 1)\recho $ECS_EXEC_TASK_ARN This will output the ARN of the task:\narn:aws:ecs:us-west-2:XXXXXXXXXX:task/retail-store-ecs-cluster/0564778486a846599b8bd6b544e5f6eb\nStart your /bin/bash interactive session in the running task.\nif [ -z ${ECS_EXEC_TASK_ARN} ]; then echo \u0026#34;ECS_EXEC_TASK_ARN is not correctly configured!\u0026#34;; else\raws ecs execute-command --cluster retail-store-ecs-cluster \\\r--task $ECS_EXEC_TASK_ARN \\\r--container application \\\r--interactive \\\r--command \u0026#34;/bin/bash\u0026#34;\rfi Scaling Up First, install the stress command:\ndnf install stress -y\nNow, issue the following command to stress 10 CPU cores with a timeout of 180 seconds:\nstress -c 10 --timeout 180\nNavigate to the Container Insights console page and select the time range to 5 minutes as shown below:\nIt will take a few minutes for the metrics to appear in CloudWatch Insights. To observe the stress spike in real-time, enable auto-refresh for 10 seconds in the CloudWatch console.\nOn the Container Insights console page, you can observe that the CPU utilization increases as the load on the ui service is increased.\nAfter observing the scaling effect, terminate your session:\nexit\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Observability with Amazon ECS",
	"tags": [],
	"description": "",
	"content": "Observability with Amazon ECS Observability is the capability to continuously generate and discover actionable insights based on signals from the system under observation. In other words, observability allows users to understand a system\u0026rsquo;s state from its external output and take appropriate action. The three pillars of observability are metrics, logs, and traces:\nMetrics Metrics represent numeric data measured over time intervals. They leverage mathematical modeling and prediction to understand the behavior of a system in both the present and future. They are useful for identifying trends and enabling mathematical modeling and prediction. Logs Logs consist of immutable, timestamped records capturing discrete events as they occur over time. They are valuable for detecting emergent and unpredictable behavior. They are particularly useful for uncovering emergent and unpredictable behavior patterns. Traces Traces depict a sequence of interconnected distributed events that outline the end-to-end journey of a request through a distributed system. They offer insights, such as latency, into the path taken by a request and its structure. They provide visibility into both the path traversed by a request as well as the structure of a request. In summary, we can break observability down into three main components: CloudWatch Metrics, CloudWatch Logs, and AWS X-Ray. Together, these form a comprehensive observability solution on AWS, covering metric monitoring, log management, and distributed tracing, respectively. These pillars work in tandem to provide users with deep insights into the behavior, performance, and reliability of their AWS environments and applications.\n"
},
{
	"uri": "//localhost:1313/2-open-telemetry/1-opentelemetry-components/",
	"title": " OpenTelemetry Components",
	"tags": [],
	"description": "",
	"content": "OpenTelemetry Collector The OpenTelemetry Collector is a versatile component designed to export telemetry data to multiple destinations, including Prometheus, AWS X-Ray, and Amazon CloudWatch. The AWS Distro for OpenTelemetry Collector represents AWS\u0026rsquo;s supported distribution of the upstream OpenTelemetry Collector. This AWS-maintained component ensures reliable integration with Amazon CloudWatch and various other supported backends, including partner ISV solutions.\nRefer to our documentation to learn about different exporters supported in AWS Distro for OpenTelemetry.\nThe OpenTelemetry Collector can be deployed using several patterns to match your architectural requirements:\nSidecar Pattern: Deploys the collector alongside your application on the same host, enabling local collection and export of telemetry data.\nECS Service Pattern: Operates as a centralized collector service, consolidating telemetry data from multiple application nodes. For comprehensive information about deployment patterns and configurations, consult the AWS blog on deployment patterns.\nOpenTelemetry Protocol The OpenTelemetry Protocol (OTLP) serves as a vendor-neutral specification for transmitting traces, metrics, and logs. It enables seamless backend transitions by requiring only configuration adjustments on the collector. OTLP establishes standardized data encoding, transport, and delivery mechanisms, ensuring future compatibility and straightforward integration.\nFor an in-depth understanding of OpenTelemetry\u0026rsquo;s components, consult the full specification. You can find a comprehensive specification of OpenTelemetry\u0026rsquo;s components.\nInstrumentation OpenTelemetry delivers extensive support for generating telemetry data across diverse libraries and frameworks. It enables both auto-instrumentation and manual instrumentation approaches to capture detailed observability data:\nAuto-Instrumentation: Collects telemetry data automatically, including traces, metrics, and logs, without requiring modifications to your application code. This method provides rapid integration with common libraries and frameworks, enabling observation of HTTP requests and other operations with minimal configuration.\nManual Instrumentation: Provides granular control through direct integration of OpenTelemetry SDKs into your codebase. This approach enables creation of custom spans, metrics, and logs, offering the flexibility to monitor specific application behaviors and detailed performance characteristics.\nThese complementary approaches can be effectively combined to monitor applications across AWS App Runner, AWS Lambda, EC2, ECS, EKS on EC2, AWS Fargate, and hybrid or on-premises environments. While auto-instrumentation delivers comprehensive coverage, manual instrumentation enables collection of specialized telemetry data.\nRefer to the OpenTelemetry specification to learn more.\n"
},
{
	"uri": "//localhost:1313/2-open-telemetry/2-adot-collector-components/",
	"title": "ADOT Collector Components",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will deploy the AWS Distro for OpenTelemetry Collector (ADOT Collector) as a sidecar container in Amazon ECS. Our retail applications, running within the same Amazon ECS task, will be configured to send monitoring data to the ADOT Collector.\nPolicies Required for ADOT Collector To operate the ADOT Collector on Amazon ECS effectively, specific IAM permissions must be attached to your ECS task role. These permissions enable the ADOT Collector to collect and transmit logs, traces, and metrics to various AWS services including CloudWatch, X-Ray, and others.\nLet\u0026rsquo;s begin by creating the IAM policy for the OpenTelemetry Collector. This policy grants the necessary permissions for comprehensive telemetry collection.\naws iam create-policy \\\r--policy-name AWSOpenTelemetryPolicy \\\r--policy-document \u0026#39;{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;logs:PutLogEvents\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:CreateLogStream\u0026#34;,\r\u0026#34;logs:DescribeLogStreams\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;xray:PutTraceSegments\u0026#34;,\r\u0026#34;xray:PutTelemetryRecords\u0026#34;,\r\u0026#34;xray:GetSamplingRules\u0026#34;,\r\u0026#34;xray:GetSamplingTargets\u0026#34;,\r\u0026#34;xray:GetSamplingStatisticSummaries\u0026#34;,\r\u0026#34;cloudwatch:PutMetricData\u0026#34;,\r\u0026#34;ec2:DescribeVolumes\u0026#34;,\r\u0026#34;ec2:DescribeTags\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r}\u0026#39;\raws iam attach-role-policy \\\r--role-name retailStoreEcsTaskRole \\\r--policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSOpenTelemetryPolicy Understanding the Default ADOT Configuration The ADOT Collector configuration specifies how telemetry data (logs, traces, and metrics) is processed and exported. AWS provides a default configuration optimized for Amazon ECS environments. You can examine the complete default configuration here.\nConfiguration Breakdown Extensions: The health_check extension enables monitoring of the collector\u0026rsquo;s operational status.\nextensions:\rhealth_check: Receivers: The otlp receiver is configured to accept telemetry data through both gRPC and HTTP protocols on designated endpoints.\nreceivers:\rotlp:\rprotocols:\rgrpc:\rendpoint: 0.0.0.0:4317\rhttp:\rendpoint: 0.0.0.0:4318 Processors: The configuration includes several processors:\nbatch/traces and batch/metrics handle the batching of trace and metric data resourcedetection automatically identifies resource attributes from environment, ECS, and EC2 sources resource manages resource attributes through setting and removal operations processors:\rbatch/traces:\rtimeout: 1s\rsend_batch_size: 50\rbatch/metrics:\rtimeout: 60s\rresourcedetection:\rdetectors:\r- env\r- ecs\r- ec2\rresource:\rattributes:\r- key: TaskDefinitionFamily\rfrom_attribute: aws.ecs.task.family\raction: insert\r- key: aws.ecs.task.family\raction: delete\r- key: InstanceId\rfrom_attribute: host.id\raction: insert\r- key: host.id\raction: delete\r- key: TaskARN\rfrom_attribute: aws.ecs.task.arn\raction: insert\r- key: aws.ecs.task.arn\raction: delete\r- key: TaskDefinitionRevision\rfrom_attribute: aws.ecs.task.revision\raction: insert\r- key: aws.ecs.task.revision\raction: delete\r- key: LaunchType\rfrom_attribute: aws.ecs.launchtype\raction: insert\r- key: aws.ecs.launchtype\raction: delete\r- key: ClusterARN\rfrom_attribute: aws.ecs.cluster.arn\raction: insert\r- key: aws.ecs.cluster.arn\raction: delete\r- key: cloud.provider\raction: delete\r- key: cloud.platform\raction: delete\r- key: cloud.account.id\raction: delete\r- key: cloud.region\raction: delete\r- key: cloud.availability_zone\raction: delete\r- key: aws.log.group.names\raction: delete\r- key: aws.log.group.arns\raction: delete\r- key: aws.log.stream.names\raction: delete\r- key: host.image.id\raction: delete\r- key: host.name\raction: delete\r- key: host.type\raction: delete Exporters: The configuration defines two exporters:\nawsxray for transmitting trace data to AWS X-Ray awsemf/application for sending metrics to Amazon CloudWatch with specific log group and namespace settings exporters:\rawsxray:\rawsemf/application:\rnamespace: ECS/AWSOTel/Application\rlog_group_name: \u0026#39;/aws/ecs/application/metrics\u0026#39;\rdimension_rollup_option: NoDimensionRollup\rresource_to_telemetry_conversion:\renabled: true Services: The configuration establishes two primary pipelines:\nA traces pipeline for processing and exporting trace data A metrics/application pipeline for handling metrics Both pipelines integrate with the health_check extension for monitoring collector health.\nservice:\rpipelines:\rtraces:\rreceivers: [otlp]\rprocessors: [resourcedetection, batch/traces]\rexporters: [awsxray]\rmetrics/application:\rreceivers: [otlp]\rprocessors: [resourcedetection, resource, batch/metrics]\rexporters: [awsemf/application]\rextensions: [health_check] "
},
{
	"uri": "//localhost:1313/2-open-telemetry/3-instrumentation/",
	"title": "Instrumentation",
	"tags": [],
	"description": "",
	"content": "\nInjecting Auto-instrumentation The AWS Distro for OpenTelemetry (ADOT) provides auto-instrumentation capabilities for multiple programming languages, including .NET, Java, Node.js, Python, and Go services running in Amazon ECS. With ADOT, you can generate traces and metrics without modifying your application code.\nWhen you integrate ADOT with your ECS tasks, you gain the ability to collect metadata from your AWS resources and managed services. This integration enables you to correlate application performance data with infrastructure metrics, helping to reduce mean time to problem resolution.\nAuto-instrumenting Java UI Application In this section, we\u0026rsquo;ll demonstrate auto-instrumentation by focusing on our Java-based UI application with the OpenTelemetry agent. While the other components in our application - catalog (written in Golang), cart (Java), and checkout (Node.js) - can also be auto-instrumented, we\u0026rsquo;ll use this single example to illustrate the principles of OpenTelemetry and auto-instrumentation.\nTo enable the OpenTelemetry agent for a Java application, you need to specify the \u0026ndash;javaagent flag at startup or set it as an environment variable. Additionally, most tracing systems require a service name to identify your application. You can define this using the OTEL_RESOURCE_ATTRIBUTES environment variable with the service.name attribute key.\nOpenTelemetry Java Agent Configuration The following table outlines the key environment variables used for configuring the OpenTelemetry Java agent:\nEnvironment Variable Description JAVA_TOOL_OPTIONS Specifies the path to the Java agent. This tells the JVM to load the OpenTelemetry agent when starting the application. OTEL_SERVICE_NAME Sets the service name for identifying your application. This name is used to associate your application\u0026rsquo;s traces with its service. OTEL_EXPORTER_OTLP_INSECURE Configures the agent to use an insecure connection (e.g., without TLS). This is used for communication with the OpenTelemetry Collector. OTEL_JAVAAGENT_ENABLED Enables the OpenTelemetry Java agent. This variable must be set to true to activate the agent for tracing and metrics collection. To deploy the ADOT collector as a sidecar, we\u0026rsquo;ll create a new revision of the task definition and update the service to use this latest version.\nFirst, we\u0026rsquo;ll register the new task definition:\naws ecs register-task-definition --cli-input-json \u0026#34;$(echo \u0026#39;{\r\u0026#34;family\u0026#34;: \u0026#34;retail-store-ecs-ui\u0026#34;,\r\u0026#34;executionRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026#39;\u0026#34;$ACCOUNT_ID\u0026#34;\u0026#39;:role/retailStoreEcsTaskExecutionRole\u0026#34;,\r\u0026#34;taskRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026#39;\u0026#34;$ACCOUNT_ID\u0026#34;\u0026#39;:role/retailStoreEcsTaskRole\u0026#34;,\r\u0026#34;networkMode\u0026#34;: \u0026#34;awsvpc\u0026#34;,\r\u0026#34;requiresCompatibilities\u0026#34;: [\u0026#34;FARGATE\u0026#34;],\r\u0026#34;cpu\u0026#34;: \u0026#34;1024\u0026#34;,\r\u0026#34;memory\u0026#34;: \u0026#34;2048\u0026#34;,\r\u0026#34;runtimePlatform\u0026#34;: {\r\u0026#34;cpuArchitecture\u0026#34;: \u0026#34;X86_64\u0026#34;,\r\u0026#34;operatingSystemFamily\u0026#34;: \u0026#34;LINUX\u0026#34;\r},\r\u0026#34;containerDefinitions\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;application\u0026#34;,\r\u0026#34;image\u0026#34;: \u0026#34;public.ecr.aws/aws-containers/retail-store-sample-ui:0.7.0\u0026#34;,\r\u0026#34;portMappings\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;application\u0026#34;,\r\u0026#34;containerPort\u0026#34;: 8080,\r\u0026#34;hostPort\u0026#34;: 8080,\r\u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;,\r\u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34;\r}\r],\r\u0026#34;essential\u0026#34;: true,\r\u0026#34;linuxParameters\u0026#34;: {\r\u0026#34;initProcessEnabled\u0026#34;: true\r},\r\u0026#34;environment\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;JAVA_TOOL_OPTIONS\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;-javaagent:/opt/aws-opentelemetry-agent.jar\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_JAVAAGENT_ENABLED\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;true\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_EXPORTER_OTLP_ENDPOINT\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;http://localhost:4317\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_EXPORTER_OTLP_INSECURE\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;true\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_SERVICE_NAME\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;ui-application\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_TRACES_EXPORTER\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;otlp\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_METRICS_EXPORTER\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;otlp\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;OTEL_LOGS_EXPORTER\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;none\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;ENDPOINTS_CATALOG\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;http://catalog\u0026#34;\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;ENDPOINTS_ASSETS\u0026#34;,\r\u0026#34;value\u0026#34;: \u0026#34;http://assets\u0026#34;\r}\r],\r\u0026#34;healthCheck\u0026#34;: {\r\u0026#34;command\u0026#34;: [\r\u0026#34;CMD-SHELL\u0026#34;,\r\u0026#34;curl -f http://localhost:8080/actuator/health || exit 1\u0026#34;\r],\r\u0026#34;interval\u0026#34;: 10,\r\u0026#34;timeout\u0026#34;: 5,\r\u0026#34;retries\u0026#34;: 3,\r\u0026#34;startPeriod\u0026#34;: 60\r},\r\u0026#34;logConfiguration\u0026#34;: {\r\u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;,\r\u0026#34;options\u0026#34;: {\r\u0026#34;awslogs-group\u0026#34;: \u0026#34;retail-store-ecs-tasks\u0026#34;,\r\u0026#34;awslogs-region\u0026#34;: \u0026#34;\u0026#39;\u0026#34;$AWS_REGION\u0026#34;\u0026#39;\u0026#34;,\r\u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ui-service\u0026#34;\r}\r}\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;aws-otel-collector\u0026#34;,\r\u0026#34;image\u0026#34;: \u0026#34;public.ecr.aws/aws-observability/aws-otel-collector:latest\u0026#34;,\r\u0026#34;essential\u0026#34;: true,\r\u0026#34;portMappings\u0026#34;: [\r{\r\u0026#34;containerPort\u0026#34;: 4317,\r\u0026#34;hostPort\u0026#34;: 4317,\r\u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;\r}\r],\r\u0026#34;command\u0026#34;: [\r\u0026#34;--config=/etc/ecs/ecs-cloudwatch-xray.yaml\u0026#34;\r],\r\u0026#34;logConfiguration\u0026#34;: {\r\u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;,\r\u0026#34;options\u0026#34;: {\r\u0026#34;awslogs-group\u0026#34;: \u0026#34;retail-store-ecs-tasks\u0026#34;,\r\u0026#34;awslogs-region\u0026#34;: \u0026#34;\u0026#39;\u0026#34;$AWS_REGION\u0026#34;\u0026#39;\u0026#34;,\r\u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;aws-otel-collector\u0026#34;,\r\u0026#34;awslogs-create-group\u0026#34;: \u0026#34;True\u0026#34;\r}\r}\r}\r]\r}\u0026#39;)\u0026#34; Next, we\u0026rsquo;ll update the ECS service for the ui service to use the new task definition revision (~ 5 min):\naws ecs update-service --cluster retail-store-ecs-cluster --service ui --task-definition retail-store-ecs-ui\raws ecs wait services-stable --cluster retail-store-ecs-cluster --services ui After updating the service, the tasks now include the aws-otel-collector sidecar:\n"
},
{
	"uri": "//localhost:1313/2-open-telemetry/",
	"title": "OpenTelemetry",
	"tags": [],
	"description": "",
	"content": "\rPrerequisites: Complete the Fundamentals \u0026amp; ECS Service Connect chapter before starting this lab.\nWhat is OpenTelemtry? OpenTelemetry is a comprehensive collection of APIs, SDKs, and tools designed to instrument, generate, collect, and export telemetry data (metrics, logs, and traces). This data helps you analyze your software\u0026rsquo;s performance and behavior in detail. By providing a standardized approach to collecting and transmitting data across various services and applications, OpenTelemetry enables deeper insights into your systems\u0026rsquo; operations.\nAWS Distro for OpenTelemtry AWS Distro for OpenTelemetry (ADOT) is a secure, production-ready, AWS-supported distribution of the Cloud Native Computing Foundation (CNCF) OpenTelemetry project.\nADOT allows you to instrument your applications just once while sending correlated logs, metrics, and traces to multiple observability backends. These backends can include:\nAmazon Managed Service for Prometheus Amazon CloudWatch AWS X-Ray Amazon OpenSearch Any OpenTelemetry Protocol (OTLP) compliant backend Amazon Managed Streaming for Apache Kafka (MSK) In this tutorial, you will learn how to implement OpenTelemetry in your AWS environment through the following steps:\nDeploying the OpenTelemetry Collector (ADOT Collector) as a sidecar container on Amazon ECS with Fargate Instrumenting application code to collect traces and logs using OpenTelemetry Analyzing the collected traces and logs in the AWS console "
},
{
	"uri": "//localhost:1313/2-open-telemetry/4-viewing-otel-metrics-and-traces/",
	"title": "Viewing Otel Metrics and Traces",
	"tags": [],
	"description": "",
	"content": "Verifying Traces and Metrics Let\u0026rsquo;s verify your monitoring setup by accessing your application through the AWS Load Balancer. First, retrieve the Load Balancer\u0026rsquo;s DNS name and use it to generate test traffic to your application.\nRETAIL_ALB=$(aws elbv2 describe-load-balancers --name retail-store-ecs-ui \\\r--query \u0026#39;LoadBalancers[0].DNSName\u0026#39; --output text)\recho ${RETAIL_ALB} Use the DNS name displayed above to access your application in a web browser. To generate meaningful traces:\nClick on individual products to view their details Open the Catalog Browse through different product categories If the cart component has not yet been deployed following the Security Lab, avoid adding items to the cart.\nThese actions should generate traces for the UI, Catalog, and Assets services. If you don\u0026rsquo;t see traces for all services immediately, wait a few minutes and refresh the CloudWatch console, as there may be a slight delay in data processing.\nTo examine the tracing, metrics, and logs data, navigate to the CloudWatch console using the link below.\nOpen Amazon CloudWatch console\rCheck AWS X-Ray Trace Map In CloudWatch, go to X-Ray traces and select Trace map. You should see a service map similar to the one shown below.\nThe Trace Map displays the relationships and interactions between your microservices and components. This visualization helps you understand how requests flow through your application architecture. You\u0026rsquo;ll notice the name ui-application in the tracing map, which corresponds to the OTEL_SERVICE_NAME we configured earlier.\nBelow the Trace Map is the Segment Timeline, which shows the different Segments the trace contains.\nTo learn more about AWS X-Ray concepts and capabilities, visit the AWS X-Ray Documentation.\nView Metrics in CloudWatch CloudWatch Metrics allows you to monitor your instrumented Java application\u0026rsquo;s performance through various OpenTelemetry metrics. These include JVM memory usage, thread counts, and garbage collection statistics, which are essential for monitoring application health and optimizing resource usage.\nTo examine the thread count metric:\nNavigate to All Metrics from the left sidebar under Metrics Select the custom namespace ECS/AWSOTel/Application Search for the metric process.runtime.jvm.threads.count View EMF Logs in CloudWatch Logs The AWS Distro for OpenTelemetry (ADOT) configuration uses the Embedded Metric Format (EMF) as an exporter, which automatically converts your application metrics into CloudWatch metrics. These measurements are also available as logs in CloudWatch Logs, providing additional context for your application\u0026rsquo;s performance.\nTo examine the structure of an EMF log entry:\nNavigate to Log groups from the left sidebar under Logs Find the Log Group /aws/ecs/application/metrics Click on the Log Group to explore the log streams Search for Specific Log Entries To find log entries related to JVM thread metrics:\nSelect Logs Insights from the left sidebar under Logs Choose the log group /aws/ecs/application/metrics Enter and run the following query to filter for JVM thread metrics: fields @timestamp, @message, @logStream, @log\r| filter @message like /jvm\\.threads/\r| sort @timestamp desc\r| limit 10 Understanding EMF Log Metrics The query results will show metrics in log format, including dimensions and AWS event information. Key components include:\nNamespace: A string representing the CloudWatch namespace for the metric Dimensions: An array of DimensionSet Metrics: An array of MetricDefinition objects For comprehensive details about the EMF format, consult the CloudWatch Embedded Metric Format Specification.\n"
},
{
	"uri": "//localhost:1313/3-clean-resources/",
	"title": "Clean Resource",
	"tags": [],
	"description": "",
	"content": "// TODO: This cleanup step will be done after completion \u0026amp; deletion of the labs.\n"
},
{
	"uri": "//localhost:1313/4-conclusion/",
	"title": "Conclution",
	"tags": [],
	"description": "",
	"content": "In conclusion, observability stands as a critical capability for modern, complex systems. It empowers us to move beyond simple monitoring by continuously generating and enabling the discovery of actionable insights derived from system signals. This allows for a profound understanding of a system\u0026rsquo;s internal state through its external manifestations, facilitating informed and timely interventions.\nThe foundational three pillars of observability – metrics, logs, and traces – each contribute uniquely to this understanding:\nMetrics provide quantitative, time-series data, essential for trend identification, capacity planning, and predictive analysis. Logs offer immutable, timestamped records of discrete events, proving invaluable for diagnosing emergent and unpredictable behaviors. Traces map the end-to-end journey of requests across distributed systems, revealing latency bottlenecks and the intricate flow of operations. On the AWS platform, these pillars are comprehensively addressed through CloudWatch Metrics, CloudWatch Logs, and AWS X-Ray. Working in synergy, these services constitute a robust observability solution, delivering in-depth visibility into the behavior, performance, and overall reliability of AWS environments and the applications they host. By effectively leveraging these tools, users can proactively manage their systems, optimize performance, and ensure a resilient and dependable operational landscape.\nNext Steps Continue your Amazon ECS learning journey by exploring these specialized workshop modules:\nAuto Scaling - Learn to dynamically scale your applications Networking - Master ECS networking concepts and implementations Observability - Implement comprehensive monitoring solutions Security - Implement robust security controls and best practices Automation - Streamline deployment workflows Storage - Integrate Amazon EFS for persistent storage Each module provides detailed hands-on experience to help you build production-ready ECS applications.\nCredits Le Minh Nghia - https://www.linkedin.com/in/minhnghia2k3/\nTran Doan Cong Ly - https://www.linkedin.com/in/trandoancongly/\nReferences Container Insights - https://catalog.workshops.aws/ecs-immersion-day/en-US/50-observability/container-insights\nOpenTelemetry - https://catalog.workshops.aws/ecs-immersion-day/en-US/50-observability/open-telemetry\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]